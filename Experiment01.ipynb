{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with K-Means clusters\n",
    "\n",
    "**An experimental algorithm to cluster data and feature engineering based on \"anomalies\" in the data**\n",
    "\n",
    "To ease the development of the algorithm, a class and multiple functions have been created. This will aid in time consuming tasks.\n",
    "\n",
    "Redudant imports exists, which sole reason is for further experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Datastore, Dataset\n",
    "\n",
    "from azureml.core.experiment import Experiment\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pandas.plotting import parallel_coordinates\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get data from Azure Machine Learning ressource and storage accounts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config(\"./config/config_2\")\n",
    "az_store = Datastore.get(ws, 'azureml_ds_b01')\n",
    "az_dataset = Dataset.get_by_name(ws, \"Petrosani_01\")\n",
    "#az_dataset_Turda = Dataset.get_by_name(ws, \"Turda_01\")\n",
    "az_default_store = ws.get_default_datastore()\n",
    "df = az_dataset.to_pandas_dataframe()\n",
    "#df_Turda_ = az_dataset_Turda.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup tools**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotCorrelationMatrix(df, graphWidth):\n",
    "    #filename = df.dataframeName\n",
    "    df = df.dropna('columns') # drop columns with NaN\n",
    "    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n",
    "    if df.shape[1] < 2:\n",
    "        print(f'No correlation plots shown: The number of non-NaN or constant columns ({df.shape[1]}) is less than 2')\n",
    "        return\n",
    "    corr = df.corr()\n",
    "    plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')\n",
    "    corrMat = plt.matshow(corr, fignum = 1)\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "    plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "    plt.gca().xaxis.tick_bottom()\n",
    "    plt.colorbar(corrMat)\n",
    "    plt.title(f'Correlation Matrix', fontsize=15)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def pd_centers(featuresUsed, centers):\n",
    "\tcolNames = list(featuresUsed)\n",
    "\tcolNames.append('prediction')\n",
    "\n",
    "\t# Zip with a column called 'prediction' (index)\n",
    "\tZ = [np.append(A, index) for index, A in enumerate(centers)]\n",
    "\n",
    "\t# Convert to pandas data frame for plotting\n",
    "\tP = pd.DataFrame(Z, columns=colNames)\n",
    "\tP['prediction'] = P['prediction'].astype(int)\n",
    "\treturn P\n",
    "\n",
    "\n",
    "# class for loading, initializing and training a logistic model with Kmeans clusters.\n",
    "class clust():\n",
    "    def _load_data(self, sklearn_load_ds):\n",
    "        data = sklearn_load_ds\n",
    "        X = pd.DataFrame(data[['Temp_Out', 'Temp_Room', 'FanSpeed']])\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, data['Abnormality'], test_size=0.3, random_state=42)\n",
    "        \n",
    "    def cmPlot(df):\n",
    "        return plotCorrelationMatrix(df, 5)\n",
    "        \n",
    "    def __init__(self, sklearn_load_ds):\n",
    "        self._load_data(sklearn_load_ds)\n",
    "    \n",
    "    \n",
    "    def classify(self, model=LogisticRegression(random_state=42, warm_start=True, class_weight=2)):\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        y_pred = model.predict(self.X_test)\n",
    "        print('Accuracy: {}'.format(accuracy_score(self.y_test, y_pred)))\n",
    "\n",
    "\n",
    "    def Kmeans(self, output='add'):\n",
    "        n_clusters = len(np.unique(self.y_train))\n",
    "        clf = KMeans(n_clusters = n_clusters, random_state=42)\n",
    "        clf.fit(self.X_train)\n",
    "        y_labels_train = clf.labels_\n",
    "        y_labels_test = clf.predict(self.X_test)\n",
    "        if output == 'add':\n",
    "            self.X_train['km_clust'] = y_labels_train\n",
    "            self.X_test['km_clust'] = y_labels_test\n",
    "        elif output == 'replace':\n",
    "            self.X_train = y_labels_train[:, np.newaxis]\n",
    "            self.X_test = y_labels_test[:, np.newaxis]\n",
    "        else:\n",
    "            raise ValueError('output should be either add or replace')\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw data exploration\n",
    "\n",
    "- Correlation matrix plotted, to observe any correlation in the raw data. \n",
    "- Transpose method used to get a statistical overview of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCorrelationMatrix(df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create new features based on existing data**\n",
    "\n",
    "This process is to get an indication of what can be classified as an anomali, for further use in the Regression Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldatestart = '2021-01-01'\n",
    "alldateend = '2021-12-31'\n",
    "\n",
    "# create features\n",
    "mask = (df['Date_Id'] > alldatestart) & (df['Date_Id'] <= alldateend)\n",
    "df_anom = df.loc[mask]\n",
    "temp_threshhold = 10\n",
    "fanspeed_threshhold = 15\n",
    "\n",
    "\n",
    "\n",
    "# define temperatur difference indicator\n",
    "df_anom['RoomTempHigher'] = np.where(df_anom['Temp_Room'] > (df_anom['Temp_Out'] - temp_threshhold), 1, 0)\n",
    "df_anom['TempDifFromMean'] = np.where((df_anom['Temp_Room'] - df_anom['Temp_Out']) > (df_anom['Temp_Room'].mean() - (df_anom['Temp_Out'].mean() + temp_threshhold)), 1, 0)\n",
    "\n",
    "# define fanspeed difference from mean indicator\n",
    "df_anom['FanSpeedHigherThanMean'] = np.where(df_anom['FanSpeed'] > (df_anom['FanSpeed'].mean() + fanspeed_threshhold), 1, 0)\n",
    "\n",
    "# define abnormality from above features\n",
    "df_anom['Abnormality'] = np.where(((df_anom['FanSpeedHigherThanMean'] == 1) & (df_anom['RoomTempHigher'] == 1)), 1, 0)\n",
    "\n",
    "\n",
    "df_anom['TempDiff'] = np.where(((df_anom['Temp_Room'] > df_anom['Temp_Out'])), df_anom['Temp_Room'] - df_anom['Temp_Out'], 0)\n",
    "df_anom['FanFreq'] = np.where(((df_anom['FanSpeed'] > df_anom['FanSpeed'].mean())), df_anom['FanSpeed'] - df_anom['FanSpeed'].mean(), 0)\n",
    "\n",
    "# define arobs\n",
    "conditions = [\n",
    "    (df_anom['FanSpeedHigherThanMean'] == 1) & (df_anom['RoomTempHigher'] == 1),\n",
    "    (df_anom['FanSpeedHigherThanMean'] == 1) & (df_anom['RoomTempHigher'] == 0),\n",
    "    (df_anom['FanSpeedHigherThanMean'] == 0) & (df_anom['RoomTempHigher'] == 1),\n",
    "    (df_anom['FanSpeedHigherThanMean'] == 0) & (df_anom['RoomTempHigher'] == 0)\n",
    "    ]\n",
    "values = [1, 0, 0, 0]\n",
    "\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments\n",
    "df_anom['Arobs'] = np.select(conditions, values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore new features in statistical format and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_df = df_anom.drop(['Location_Id', 'Date_Id', 'Arobs', 'Temp_Id'], 1)\n",
    "select_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explore cluster K-means algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(select_df)\n",
    "\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "model = kmeans.fit(X)\n",
    "print(\"model\\n\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = model.cluster_centers_\n",
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = pd_centers(select_df, centers)\n",
    "P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting out scaled values and define cluster**\n",
    "\n",
    "Plotted values are fanspeed and out temps. The line indicates the two different clusters, which will be used for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[10], X[5], c='b')\n",
    "\n",
    "plt.xlabel('Fanspeed')\n",
    "plt.ylabel('Temp_Out')\n",
    "plt.title(label=\"\")\n",
    "plt.ylim(-1,1.5)\n",
    "plt.xlim(-1,1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[10], X[5], c='b')\n",
    "plt.plot(centers[1], centers[0], c='r')\n",
    "plt.plot(X[10], X[10], c='g')\n",
    "\n",
    "plt.xlabel('Fanspeed')\n",
    "plt.ylabel('Temp_Out')\n",
    "plt.title(label=\"G:Temp_Out | R: Cluster Center\")\n",
    "plt.ylim(-1,1.5)\n",
    "plt.xlim(-1,1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clus = clust(sklearn_load_ds=select_df)\n",
    "\n",
    "result = clus.Kmeans(output='replace').classify()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "173f3282cf63b63e511481779b17cb90652ab3fef934cc002e06f64508e27aae"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
